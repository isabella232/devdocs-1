<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8">
    
    <title>Quasi-Monte Carlo submodule (scipy.stats.qmc) &mdash; SciPy v1.7.0.dev0+5ac5f63 Reference Guide</title>
    
    <link rel="stylesheet" type="text/css" href="_static/css/spc-bootstrap.css">
    <link rel="stylesheet" type="text/css" href="_static/css/spc-extend.css">
    <link rel="stylesheet" href="_static/scipy.css" type="text/css" >
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" >
    
    <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/scipy-mathjax/MathJax.js?config=scipy-mathjax"></script>
    <script type="text/javascript" src="_static/js/copybutton.js"></script>
    <link rel="index" title="Index" href="genindex.html" >
    <link rel="search" title="Search" href="search.html" >
    <link rel="top" title="SciPy v1.7.0.dev0+5ac5f63 Reference Guide" href="index.html" >
    <link rel="up" title="Statistical functions (scipy.stats)" href="stats.html" >
    <link rel="next" title="scipy.stats.qmc.QMCEngine" href="generated/scipy.stats.qmc.QMCEngine.html" >
    <link rel="prev" title="scipy.stats.BinomTestResult.proportion_ci" href="generated/scipy.stats.BinomTestResult.proportion_ci.html" > 
  </head>
  <body>

<div class="container">
  <div class="top-scipy-org-logo-header">
    <a href="index.html">
      <img style="border: 0;" alt="SciPy" src="_static/img/scipy_org_logo.png"></a>
    </div>
  </div>
</div>


    <div class="container">
      <div class="main">
        
	<div class="row-fluid">
	  <div class="span12">
	    <div class="spc-navbar">
              
    <ul class="nav nav-pills pull-left">
        <li class="active"><a href="https://scipy.org/">SciPy.org</a></li>
        <li class="active"><a href="https://docs.scipy.org/">Docs</a></li>
	
        <li class="active"><a href="index.html">SciPy v1.7.0.dev0+5ac5f63 Reference Guide</a></li>
	
          <li class="active"><a href="stats.html" accesskey="U">Statistical functions (<code class="xref py py-mod docutils literal notranslate"><span class="pre">scipy.stats</span></code>)</a></li> 
    </ul>
              
              
    <ul class="nav nav-pills pull-right">
      <li class="active">
        <a href="genindex.html" title="General Index"
           accesskey="I">index</a>
      </li>
      <li class="active">
        <a href="py-modindex.html" title="Python Module Index"
           >modules</a>
      </li>
      <li class="active">
        <a href="generated/scipy.stats.qmc.QMCEngine.html" title="scipy.stats.qmc.QMCEngine"
           accesskey="N">next</a>
      </li>
      <li class="active">
        <a href="generated/scipy.stats.BinomTestResult.proportion_ci.html" title="scipy.stats.BinomTestResult.proportion_ci"
           accesskey="P">previous</a>
      </li>
    </ul>
              
	    </div>
	  </div>
	</div>
        

	<div class="row-fluid">
          <div class="span9">
            
        <div class="bodywrapper">
          <div class="body" id="spc-section-body">
            
  <span class="target" id="module-scipy.stats.qmc"></span><div class="section" id="quasi-monte-carlo-submodule-scipy-stats-qmc">
<h1>Quasi-Monte Carlo submodule (<a class="reference internal" href="#module-scipy.stats.qmc" title="scipy.stats.qmc"><code class="xref py py-mod docutils literal notranslate"><span class="pre">scipy.stats.qmc</span></code></a>)<a class="headerlink" href="#quasi-monte-carlo-submodule-scipy-stats-qmc" title="Permalink to this headline">¶</a></h1>
<p>This module provides Quasi-Monte Carlo generators and associated helper
functions.</p>
<div class="section" id="quasi-monte-carlo">
<h2>Quasi-Monte Carlo<a class="headerlink" href="#quasi-monte-carlo" title="Permalink to this headline">¶</a></h2>
<div class="section" id="engines">
<h3>Engines<a class="headerlink" href="#engines" title="Permalink to this headline">¶</a></h3>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/scipy.stats.qmc.QMCEngine.html#scipy.stats.qmc.QMCEngine" title="scipy.stats.qmc.QMCEngine"><code class="xref py py-obj docutils literal notranslate"><span class="pre">QMCEngine</span></code></a>(d[, seed])</p></td>
<td><p>A generic Quasi-Monte Carlo sampler class meant for subclassing.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/scipy.stats.qmc.Sobol.html#scipy.stats.qmc.Sobol" title="scipy.stats.qmc.Sobol"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Sobol</span></code></a>(d[, scramble, seed])</p></td>
<td><p>Engine for generating (scrambled) Sobol’ sequences.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/scipy.stats.qmc.Halton.html#scipy.stats.qmc.Halton" title="scipy.stats.qmc.Halton"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Halton</span></code></a>(d[, scramble, seed])</p></td>
<td><p>Halton sequence.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/scipy.stats.qmc.LatinHypercube.html#scipy.stats.qmc.LatinHypercube" title="scipy.stats.qmc.LatinHypercube"><code class="xref py py-obj docutils literal notranslate"><span class="pre">LatinHypercube</span></code></a>(d[, centered, seed])</p></td>
<td><p>Latin hypercube sampling (LHS).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/scipy.stats.qmc.OrthogonalLatinHypercube.html#scipy.stats.qmc.OrthogonalLatinHypercube" title="scipy.stats.qmc.OrthogonalLatinHypercube"><code class="xref py py-obj docutils literal notranslate"><span class="pre">OrthogonalLatinHypercube</span></code></a>(d[, seed])</p></td>
<td><p>Orthogonal array-based Latin hypercube sampling (OA-LHS).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/scipy.stats.qmc.MultinomialQMC.html#scipy.stats.qmc.MultinomialQMC" title="scipy.stats.qmc.MultinomialQMC"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MultinomialQMC</span></code></a>(pvals[, engine, seed])</p></td>
<td><p>QMC sampling from a multinomial distribution.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/scipy.stats.qmc.MultivariateNormalQMC.html#scipy.stats.qmc.MultivariateNormalQMC" title="scipy.stats.qmc.MultivariateNormalQMC"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MultivariateNormalQMC</span></code></a>(mean[, cov, cov_root, …])</p></td>
<td><p>QMC sampling from a multivariate Normal <span class="math notranslate nohighlight">\(N(\mu, \Sigma)\)</span>.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="helpers">
<h3>Helpers<a class="headerlink" href="#helpers" title="Permalink to this headline">¶</a></h3>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/scipy.stats.qmc.discrepancy.html#scipy.stats.qmc.discrepancy" title="scipy.stats.qmc.discrepancy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">discrepancy</span></code></a>(sample[, iterative, method])</p></td>
<td><p>Discrepancy of a given sample.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/scipy.stats.qmc.update_discrepancy.html#scipy.stats.qmc.update_discrepancy" title="scipy.stats.qmc.update_discrepancy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">update_discrepancy</span></code></a>(x_new, sample, initial_disc)</p></td>
<td><p>Update the centered discrepancy with a new sample.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/scipy.stats.qmc.scale.html#scipy.stats.qmc.scale" title="scipy.stats.qmc.scale"><code class="xref py py-obj docutils literal notranslate"><span class="pre">scale</span></code></a>(sample, l_bounds, u_bounds[, reverse])</p></td>
<td><p>Sample scaling from unit hypercube to different bounds.</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="introduction-to-quasi-monte-carlo">
<h2>Introduction to Quasi-Monte Carlo<a class="headerlink" href="#introduction-to-quasi-monte-carlo" title="Permalink to this headline">¶</a></h2>
<p>Quasi-Monte Carlo (QMC) methods <a class="reference internal" href="#rbfd6def8ed08-1" id="id1">[1]</a>, <a class="reference internal" href="#rbfd6def8ed08-2" id="id2">[2]</a>, <a class="reference internal" href="#rbfd6def8ed08-3" id="id3">[3]</a> provide an
<span class="math notranslate nohighlight">\(n \times d\)</span> array of numbers in <span class="math notranslate nohighlight">\([0,1]\)</span>. They can be used in
place of <span class="math notranslate nohighlight">\(n\)</span> points from the <span class="math notranslate nohighlight">\(U[0,1]^{d}\)</span> distribution. Compared to
random points, QMC points are designed to have fewer gaps and clumps. This is
quantified by discrepancy measures <a class="reference internal" href="#rbfd6def8ed08-4" id="id4">[4]</a>. From the Koksma-Hlawka
inequality <a class="reference internal" href="#rbfd6def8ed08-5" id="id5">[5]</a> we know that low discrepancy reduces a bound on
integration error. Averaging a function <span class="math notranslate nohighlight">\(f\)</span> over <span class="math notranslate nohighlight">\(n\)</span> QMC points
can achieve an integration error close to <span class="math notranslate nohighlight">\(O(n^{-1})\)</span> for well
behaved functions <a class="reference internal" href="#rbfd6def8ed08-2" id="id6">[2]</a>.</p>
<p>Most QMC constructions are designed for special values of <span class="math notranslate nohighlight">\(n\)</span>
such as powers of 2 or large primes. Changing the sample
size by even one can degrade their performance, even their
rate of convergence <a class="reference internal" href="#rbfd6def8ed08-6" id="id7">[6]</a>. For instance <span class="math notranslate nohighlight">\(n=100\)</span> points may give less
accuracy than <span class="math notranslate nohighlight">\(n=64\)</span> if the method was designed for <span class="math notranslate nohighlight">\(n=2^m\)</span>.</p>
<p>Some QMC constructions are extensible in <span class="math notranslate nohighlight">\(n\)</span>: we can find
another special sample size <span class="math notranslate nohighlight">\(n' &gt; n\)</span> and often an infinite
sequence of increasing special sample sizes. Some QMC
constructions are extensible in <span class="math notranslate nohighlight">\(d\)</span>: we can increase the dimension,
possibly to some upper bound, and typically without requiring
special values of <span class="math notranslate nohighlight">\(d\)</span>. Some QMC methods are extensible in
both <span class="math notranslate nohighlight">\(n\)</span> and <span class="math notranslate nohighlight">\(d\)</span>.</p>
<p>QMC points are deterministic. That makes it hard to estimate the accuracy of
integrals estimated by averages over QMC points. Randomized QMC (RQMC) <a class="reference internal" href="#rbfd6def8ed08-7" id="id8">[7]</a>
points are constructed so that each point is individually <span class="math notranslate nohighlight">\(U[0,1]^{d}\)</span>
while collectively the <span class="math notranslate nohighlight">\(n\)</span> points retain their low discrepancy.
One can make <span class="math notranslate nohighlight">\(R\)</span> independent replications of RQMC points to
see how stable a computation is. From <span class="math notranslate nohighlight">\(R\)</span> independent values,
a t-test (or bootstrap t-test <a class="reference internal" href="#rbfd6def8ed08-8" id="id9">[8]</a>) then gives approximate confidence
intervals on the mean value. Some RQMC methods produce a
root mean squared error that is actually <span class="math notranslate nohighlight">\(o(1/n)\)</span> and smaller than
the rate seen in unrandomized QMC. An intuitive explanation is
that the error is a sum of many small ones and random errors
cancel in a way that deterministic ones do not. RQMC also
has advantages on integrands that are singular or, for other
reasons, fail to be Riemann integrable.</p>
<p>(R)QMC cannot beat Bahkvalov’s curse of dimension (see <a class="reference internal" href="#rbfd6def8ed08-9" id="id10">[9]</a>). For
any random or deterministic method, there are worst case functions
that will give it poor performance in high dimensions. A worst
case function for QMC might be 0 at all n points but very
large elsewhere. Worst case analyses get very pessimistic
in high dimensions. (R)QMC can bring a great improvement over
MC when the functions on which it is used are not worst case.
For instance (R)QMC can be especially effective on integrands
that are well approximated by sums of functions of
some small number of their input variables at a time <a class="reference internal" href="#rbfd6def8ed08-10" id="id11">[10]</a>, <a class="reference internal" href="#rbfd6def8ed08-11" id="id12">[11]</a>.
That property is often a surprising finding about those functions.</p>
<p>Also, to see an improvement over IID MC, (R)QMC requires a bit of smoothness of
the integrand, roughly the mixed first order derivative in each direction,
<span class="math notranslate nohighlight">\(\partial^d f/\partial x_1 \cdots \partial x_d\)</span>, must be integral.
For instance, a function that is 1 inside the hypersphere and 0 outside of it
has infinite variation in the sense of Hardy and Krause for any dimension
<span class="math notranslate nohighlight">\(d = 2\)</span>.</p>
<p>Scrambled nets are a kind of RQMC that have some valuable robustness
properties <a class="reference internal" href="#rbfd6def8ed08-12" id="id13">[12]</a>. If the integrand is square integrable, they give variance
<span class="math notranslate nohighlight">\(var_{SNET} = o(1/n)\)</span>. There is a finite upper bound on
<span class="math notranslate nohighlight">\(var_{SNET} / var_{MC}\)</span> that holds simultaneously for every square
integrable integrand. Scrambled nets satisfy a strong law of large numbers
for <span class="math notranslate nohighlight">\(f\)</span> in <span class="math notranslate nohighlight">\(L^p\)</span> when <span class="math notranslate nohighlight">\(p&gt;1\)</span>. In some
special cases there is a central limit theorem <a class="reference internal" href="#rbfd6def8ed08-13" id="id14">[13]</a>. For smooth enough
integrands they can achieve RMSE nearly <span class="math notranslate nohighlight">\(O(n^{-3})\)</span>. See <a class="reference internal" href="#rbfd6def8ed08-12" id="id15">[12]</a>
for references about these properties.</p>
<p>The main kinds of QMC methods are lattice rules <a class="reference internal" href="#rbfd6def8ed08-14" id="id16">[14]</a> and digital
nets and sequences <a class="reference internal" href="#rbfd6def8ed08-2" id="id17">[2]</a>, <a class="reference internal" href="#rbfd6def8ed08-15" id="id18">[15]</a>. The theories meet up in polynomial
lattice rules <a class="reference internal" href="#rbfd6def8ed08-16" id="id19">[16]</a> which can produce digital nets. Lattice rules
require some form of search for good constructions. For digital
nets there are widely used default constructions.</p>
<p>The most widely used QMC methods are Sobol’ sequences <a class="reference internal" href="#rbfd6def8ed08-17" id="id20">[17]</a>.
These are digital nets. They are extensible in both <span class="math notranslate nohighlight">\(n\)</span> and <span class="math notranslate nohighlight">\(d\)</span>.
They can be scrambled. The special sample sizes are powers
of 2. Another popular method are Halton sequences <a class="reference internal" href="#rbfd6def8ed08-18" id="id21">[18]</a>.
The constructions resemble those of digital nets. The earlier
dimensions have much better equidistribution properties than
later ones. There are essentially no special sample sizes.
They are not thought to be as accurate as Sobol’ sequences.
They can be scrambled. The nets of Faure <a class="reference internal" href="#rbfd6def8ed08-19" id="id22">[19]</a> are also widely
used. All dimensions are equally good, but the special sample
sizes grow rapidly with dimension <span class="math notranslate nohighlight">\(d\)</span>. They can be scrambled.
The nets of Niederreiter and Xing <a class="reference internal" href="#rbfd6def8ed08-20" id="id23">[20]</a> have the best asymptotic
properties but have not shown good empirical performance <a class="reference internal" href="#rbfd6def8ed08-21" id="id24">[21]</a>.</p>
<p>Higher order digital nets are formed by a digit interleaving process
in the digits of the constructed points. They can achieve higher
levels of asymptotic accuracy given higher smoothness conditions on <span class="math notranslate nohighlight">\(f\)</span>
and they can be scrambled <a class="reference internal" href="#rbfd6def8ed08-22" id="id25">[22]</a>. There is little or no empirical work
showing the improved rate to be attained.</p>
<p>Using QMC is like using the entire period of a small random
number generator. The constructions are similar and so
therefore are the computational costs <a class="reference internal" href="#rbfd6def8ed08-23" id="id26">[23]</a>.</p>
<p>(R)QMC is sometimes improved by passing the points through
a baker’s transformation (tent function) prior to using them.
That function has the form <span class="math notranslate nohighlight">\(1-2|x-1/2|\)</span>. As <span class="math notranslate nohighlight">\(x\)</span> goes from 0 to
1, this function goes from 0 to 1 and then back. It is very
useful to produce a periodic function for lattice rules <a class="reference internal" href="#rbfd6def8ed08-14" id="id27">[14]</a>,
and sometimes it improves the convergence rate <a class="reference internal" href="#rbfd6def8ed08-24" id="id28">[24]</a>.</p>
<p>It is not straightforward to apply QMC methods to Markov
chain Monte Carlo (MCMC).  We can think of MCMC as using
<span class="math notranslate nohighlight">\(n=1\)</span> point in <span class="math notranslate nohighlight">\([0,1]^{d}\)</span> for very large <span class="math notranslate nohighlight">\(d\)</span>, with
ergodic results corresponding to <span class="math notranslate nohighlight">\(d \to \infty\)</span>. One proposal is
in <a class="reference internal" href="#rbfd6def8ed08-25" id="id29">[25]</a> and under strong conditions an improved rate of convergence
has been shown <a class="reference internal" href="#rbfd6def8ed08-26" id="id30">[26]</a>.</p>
<p>Returning to Sobol’ points: there are many versions depending
on what are called direction numbers. Those are the result of
searches and are tabulated. A very widely used set of direction
numbers come from <a class="reference internal" href="#rbfd6def8ed08-27" id="id31">[27]</a>. It is extensible in dimension up to
<span class="math notranslate nohighlight">\(d=21201\)</span>.</p>
<div class="section" id="references">
<h3>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h3>
<dl class="citation">
<dt class="label" id="rbfd6def8ed08-1"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p>Owen, Art B. “Monte Carlo Book: the Quasi-Monte Carlo parts.” (2019).</p>
</dd>
<dt class="label" id="rbfd6def8ed08-2"><span class="brackets">2</span><span class="fn-backref">(<a href="#id2">1</a>,<a href="#id6">2</a>,<a href="#id17">3</a>)</span></dt>
<dd><p>Niederreiter, Harald. Random number generation and quasi-Monte Carlo
methods. Society for Industrial and Applied Mathematics, 1992.</p>
</dd>
<dt class="label" id="rbfd6def8ed08-3"><span class="brackets"><a class="fn-backref" href="#id3">3</a></span></dt>
<dd><p>Dick, Josef, Frances Y. Kuo, and Ian H. Sloan. “High-dimensional
integration: the quasi-Monte Carlo way.” Acta Numerica 22 (2013): 133.</p>
</dd>
<dt class="label" id="rbfd6def8ed08-4"><span class="brackets"><a class="fn-backref" href="#id4">4</a></span></dt>
<dd><p>Aho, A. V., C. Aistleitner, T. Anderson, K. Appel, V. Arnol’d, N.
Aronszajn, D. Asotsky et al. “W. Chen et al.(eds.), A Panorama of
Discrepancy Theory (2014): 679. Sringer International Publishing,
Switzerland.</p>
</dd>
<dt class="label" id="rbfd6def8ed08-5"><span class="brackets"><a class="fn-backref" href="#id5">5</a></span></dt>
<dd><p>Hickernell, Fred J. “Koksma-Hlawka Inequality.” Wiley StatsRef:
Statistics Reference Online (2014).</p>
</dd>
<dt class="label" id="rbfd6def8ed08-6"><span class="brackets"><a class="fn-backref" href="#id7">6</a></span></dt>
<dd><p>Owen, Art B. “On dropping the first Sobol’ point.” arXiv preprint
arXiv:2008.08051 (2020).</p>
</dd>
<dt class="label" id="rbfd6def8ed08-7"><span class="brackets"><a class="fn-backref" href="#id8">7</a></span></dt>
<dd><p>L’Ecuyer, Pierre, and Christiane Lemieux. “Recent advances in randomized
quasi-Monte Carlo methods.” In Modeling uncertainty, pp. 419-474. Springer,
New York, NY, 2002.</p>
</dd>
<dt class="label" id="rbfd6def8ed08-8"><span class="brackets"><a class="fn-backref" href="#id9">8</a></span></dt>
<dd><p>DiCiccio, Thomas J., and Bradley Efron. “Bootstrap confidence
intervals.” Statistical science (1996): 189-212.</p>
</dd>
<dt class="label" id="rbfd6def8ed08-9"><span class="brackets"><a class="fn-backref" href="#id10">9</a></span></dt>
<dd><p>Dimov, Ivan T. Monte Carlo methods for applied scientists. World
Scientific, 2008.</p>
</dd>
<dt class="label" id="rbfd6def8ed08-10"><span class="brackets"><a class="fn-backref" href="#id11">10</a></span></dt>
<dd><p>Caflisch, Russel E., William J. Morokoff, and Art B. Owen. Valuation of
mortgage backed securities using Brownian bridges to reduce effective
dimension. Journal of Computational Finance, (1997): 1, no. 1 27-46.</p>
</dd>
<dt class="label" id="rbfd6def8ed08-11"><span class="brackets"><a class="fn-backref" href="#id12">11</a></span></dt>
<dd><p>Sloan, Ian H., and Henryk Wozniakowski. “When are quasi-Monte Carlo
algorithms efficient for high dimensional integrals?.” Journal of Complexity
14, no. 1 (1998): 1-33.</p>
</dd>
<dt class="label" id="rbfd6def8ed08-12"><span class="brackets">12</span><span class="fn-backref">(<a href="#id13">1</a>,<a href="#id15">2</a>)</span></dt>
<dd><p>Owen, Art B., and Daniel Rudolf “A strong law of large numbers for
scrambled net integration.” SIAM Review, to appear.</p>
</dd>
<dt class="label" id="rbfd6def8ed08-13"><span class="brackets"><a class="fn-backref" href="#id14">13</a></span></dt>
<dd><p>Loh, Wei-Liem. “On the asymptotic distribution of scrambled net
quadrature.” The Annals of Statistics 31, no. 4 (2003): 1282-1324.</p>
</dd>
<dt class="label" id="rbfd6def8ed08-14"><span class="brackets">14</span><span class="fn-backref">(<a href="#id16">1</a>,<a href="#id27">2</a>)</span></dt>
<dd><p>Sloan, Ian H. and S. Joe. Lattice methods for multiple integration.
Oxford University Press, 1994.</p>
</dd>
<dt class="label" id="rbfd6def8ed08-15"><span class="brackets"><a class="fn-backref" href="#id18">15</a></span></dt>
<dd><p>Dick, Josef, and Friedrich Pillichshammer. Digital nets and sequences:
discrepancy theory and quasi-Monte Carlo integration. Cambridge University
Press, 2010.</p>
</dd>
<dt class="label" id="rbfd6def8ed08-16"><span class="brackets"><a class="fn-backref" href="#id19">16</a></span></dt>
<dd><p>Dick, Josef, F. Kuo, Friedrich Pillichshammer, and I. Sloan.
“Construction algorithms for polynomial lattice rules for multivariate
integration.” Mathematics of computation 74, no. 252 (2005): 1895-1921.</p>
</dd>
<dt class="label" id="rbfd6def8ed08-17"><span class="brackets"><a class="fn-backref" href="#id20">17</a></span></dt>
<dd><p>Sobol’, Il’ya Meerovich. “On the distribution of points in a cube and
the approximate evaluation of integrals.” Zhurnal Vychislitel’noi Matematiki
i Matematicheskoi Fiziki 7, no. 4 (1967): 784-802.</p>
</dd>
<dt class="label" id="rbfd6def8ed08-18"><span class="brackets"><a class="fn-backref" href="#id21">18</a></span></dt>
<dd><p>Halton, John H. “On the efficiency of certain quasi-random sequences of
points in evaluating multi-dimensional integrals.” Numerische Mathematik 2,
no. 1 (1960): 84-90.</p>
</dd>
<dt class="label" id="rbfd6def8ed08-19"><span class="brackets"><a class="fn-backref" href="#id22">19</a></span></dt>
<dd><p>Faure, Henri. “Discrepance de suites associees a un systeme de
numeration (en dimension s).” Acta arithmetica 41, no. 4 (1982): 337-351.</p>
</dd>
<dt class="label" id="rbfd6def8ed08-20"><span class="brackets"><a class="fn-backref" href="#id23">20</a></span></dt>
<dd><p>Niederreiter, Harold, and Chaoping Xing. “Low-discrepancy sequences and
global function fields with many rational places.” Finite Fields and their
applications 2, no. 3 (1996): 241-273.</p>
</dd>
<dt class="label" id="rbfd6def8ed08-21"><span class="brackets"><a class="fn-backref" href="#id24">21</a></span></dt>
<dd><p>Hong, Hee Sun, and Fred J. Hickernell. “Algorithm 823: Implementing
scrambled digital sequences.” ACM Transactions on Mathematical Software
(TOMS) 29, no. 2 (2003): 95-109.</p>
</dd>
<dt class="label" id="rbfd6def8ed08-22"><span class="brackets"><a class="fn-backref" href="#id25">22</a></span></dt>
<dd><p>Dick, Josef. “Higher order scrambled digital nets achieve the optimal
rate of the root mean square error for smooth integrands.” The Annals of
Statistics 39, no. 3 (2011): 1372-1398.</p>
</dd>
<dt class="label" id="rbfd6def8ed08-23"><span class="brackets"><a class="fn-backref" href="#id26">23</a></span></dt>
<dd><p>Niederreiter, Harald. “Multidimensional numerical integration using
pseudorandom numbers.” In Stochastic Programming 84 Part I, pp. 17-38.
Springer, Berlin, Heidelberg, 1986.</p>
</dd>
<dt class="label" id="rbfd6def8ed08-24"><span class="brackets"><a class="fn-backref" href="#id28">24</a></span></dt>
<dd><p>Hickernell, Fred J. “Obtaining O (N-2+e) Convergence for Lattice
Quadrature Rules.” In Monte Carlo and Quasi-Monte Carlo Methods 2000,
pp. 274-289. Springer, Berlin, Heidelberg, 2002.</p>
</dd>
<dt class="label" id="rbfd6def8ed08-25"><span class="brackets"><a class="fn-backref" href="#id29">25</a></span></dt>
<dd><p>Owen, Art B., and Seth D. Tribble. “A quasi-Monte Carlo Metropolis
algorithm.” Proceedings of the National Academy of Sciences 102, no. 25
(2005): 8844-8849.</p>
</dd>
<dt class="label" id="rbfd6def8ed08-26"><span class="brackets"><a class="fn-backref" href="#id30">26</a></span></dt>
<dd><p>Chen, Su. “Consistency and convergence rate of Markov chain quasi Monte
Carlo with examples.” PhD diss., Stanford University, 2011.</p>
</dd>
<dt class="label" id="rbfd6def8ed08-27"><span class="brackets"><a class="fn-backref" href="#id31">27</a></span></dt>
<dd><p>Joe, Stephen, and Frances Y. Kuo. “Constructing Sobol sequences with
better two-dimensional projections.” SIAM Journal on Scientific Computing
30, no. 5 (2008): 2635-2654.</p>
</dd>
</dl>
</div>
</div>
</div>


          </div>
        </div>
          </div>
      <div class="spc-rightsidebar span3">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Quasi-Monte Carlo submodule (<code class="xref py py-mod docutils literal notranslate"><span class="pre">scipy.stats.qmc</span></code>)</a><ul>
<li><a class="reference internal" href="#quasi-monte-carlo">Quasi-Monte Carlo</a><ul>
<li><a class="reference internal" href="#engines">Engines</a></li>
<li><a class="reference internal" href="#helpers">Helpers</a></li>
</ul>
</li>
<li><a class="reference internal" href="#introduction-to-quasi-monte-carlo">Introduction to Quasi-Monte Carlo</a><ul>
<li><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="generated/scipy.stats.BinomTestResult.proportion_ci.html"
                        title="previous chapter">scipy.stats.BinomTestResult.proportion_ci</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="generated/scipy.stats.qmc.QMCEngine.html"
                        title="next chapter">scipy.stats.qmc.QMCEngine</a></p>
<div id="searchbox" style="display: none" role="search">
  <h4>Quick search</h4>
    <div>
    <form class="search" action="search.html" method="get">
      <input type="text" style="width: inherit;" name="q" />
      <input type="submit" value="search" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
        </div>
      </div>
    </div>

    <div class="container container-navbar-bottom">
      <div class="spc-navbar">
        
      </div>
    </div>
    <div class="container">
    <div class="footer">
    <div class="row-fluid">
    <ul class="inline pull-left">
      <li>
        &copy; Copyright 2008-2021, The SciPy community.
      </li>
      <li>
      Last updated on Feb 20, 2021.
      </li>
      <li>
      Created using <a href="https://www.sphinx-doc.org">Sphinx</a> 3.5.1.
      </li>
    </ul>
    </div>
    </div>
    </div>
  </body>
</html>